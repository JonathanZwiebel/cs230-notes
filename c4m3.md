# Detection Algorithms

# Object Localization
Classification: Given an image, determine if a particular thing is in it
Classification with localization: Algorithm needs to put bounding box around the object
Detection: Find multiple objects and label them along with their position

Image classification is done with standard conv nets
Given image we know how to get a softmax output where outputs are different labels 

To make bounding box, have ConvNet output b_x, b_y, b_h, and b_w
Upper left is 0,0
Lower right is 1,1
Midpoint and dimensions are now in the output

Need to output a class and 4 output labels
ex: class can be 1 (pedestrian), 2 (car), 3 (motorcycle), 4 (background)

y = [p_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3]
p_c is if there is an object (1, 2, or 3)
If there is object then give location, dimensions, and class as a softmax
Training set will need bounding box

If there is no object?
y = [0, ?, ?, ?, ?, ?, ?] Doesn't matter what the other labels are
ex: car
y = [1, b_x, b_y, b_h, b_w, 0, 1, 0]

Loss function
L(y_hat, y) = SSD(y_hat, y) if y1 = 1
L(y_hat, y) = (y1_hat - y1)^2 if y1 = 0

Only care about the other terms if there actually is an image
If there is no image just penalize the value

# Landmark Detection
More generally have an NN output x and y coords of important points

ex: you want the alg to find the corner of someone's eyes
The final layer of the NN should have l_x and l_y for an eye

If we want to find all 4 corners then we want l1_x, l1_y, l2_x, l2_y, l3_x, l3_y, l4_x, l4_y
Let's say you want 64 landmarks on the face

Create a labeled dataset with the 64 landmarks
ConvNet output should output 0 or 1 for face along with coordinates for the 64 landmarks
This example would have 1 + 2*64 = 129 output units

# Object Detection
Using a Conv Net for detection with sliding window
ex: Given image, put bounding boxes around the cars in the image
Training set is just images (either tightly cropped cars or not cars) with labels
You can use the training set to train a CNN to output a probability of car

You pick a window size, window a small region of the image, feed it into CNN, keep sliding the window
Once the CNN finds an window of high probability you are good
The window has size and stride
Then repeat with a larger window

Sliding windows is very computationally complex

# Convolutional Implementation of Sliding Windows
Turning FC layers into conv layers

14x14x3 
--> 5x5 filter
10x10x16
--> 2x2 pool
5x5x16
--> flatten
400
--> fc 
400
--> softmax
4

We can implement the flatten as 400 5x5x16 filters with ReLU
We can implement the fc as 400 1x1x400 filters with ReLU
We can implement the softmax as 4 1x1x400 filters with softmax

All of our units are now implemented as conv or pool layers

ex:
14x14x3 (Input)
--> CONV 5x5
10x10x16
--> POOL 2x2
5x5x16
--> CONV 5x5
1x1x400
--> CONV 1x1
1x1x400
--> CONV 1x1
1x1x4 (Output)

ex: Test set image is 16x16x3
In the original sliding windows you would generate 14x14 windows over the image and slide them over
Each different 14x14 window will give you a different input

Much of the computation is repeated
Specifically you run the exact same conv net on the image
16x16x3 (Input)
--> CONV 5x5
12x12x16
--> POOL 2x2
6x6x16
--> CONV 5x5
2x2x400
--> CONV 1x1
2x2x400
--> CONV 1x1
2x2x4 (Output)

The different XY pixels in the image correspond to different regions of the image
A single pass through the CNN allows you to make a bunch of different positions
The position of the bounding boxes isn't the most accurate

# Bounding Box Predictions
YOLO algorihtm
You only look once

ex: 100x100 input image
Place down a grid over the image
Use classification and localization and apply to each cell of the grid
Each cell is labeled seperately 

Each grid cell gives a vector of outputs + position
Your output is cell dimensions by vector size

Input is 100x100x3 
CNN outputs
3x3x8 output (assuming 3x3 cells)
For each output you can contribute an appropriate amount to the loss

in practice a 19x19 grid is good
Assign the midpoint of the object to a grid a cell

# Intersection over Union
IoU function computes the intersection divided by the union of the two bounding boxes
AB / (A + B - AB)
Correctish if IoU is >= 0.5

# Non-max Suppression
ex: you put 19x19 grid over an image
A car is in many gridpoints
The car's midpoint is just in one cell

It is common for a small cell to output a value for dimensions greater than 1
Highlight the bounding box with highest probability
Supress the ones with high overlap
Repeat
Get rid of the suppressed values
Stick with the non-suppressed values

1. Discard all cells with p_c below some threshold
2. Run non-max suppression, discarding values with IoU > 0.5

If there are multiple classes then carry out non-max suppression individually for each class

# Anchor Boxes
Each grid cell can only detect a single box

Having a softmax layer might not be the best
Predefine anchor box shapes
Now each prediction predicts multiple anchor boxes
Each output vector is the 8 (or more) values stacked up on top of eachother

Previously: each object in training image is assigned to grid cell that contains the midpoint
With anchor boxes: Each object is assigned to grid cell with midpoint but is assigned to anchor box with highest IoU
Object gets assigned to grid cell, anchor box pair

# YOLO Algorithm
ex:
y is 3x3(cells) x2 (anchors) x8 (classes)
You have two anchor boxes

Train CNN that inputs 100x100x3 and outputs a 3x3x16 image

All together
ex: you have 9 grid cells each with 2 anchor
Each cell outputs 2 bounding boxes, most with low probability

**QUESTION: How the fuck is detection done when objects are split**

# Region Proposals
Use segmentation algorithm to segment object into blobs and put bounding boxes around each blob
Fast R-CNN: Use convolutional implementation of sliding windows to classify all proposed regions together
Faster R-CNN: Use CNN to propose region
