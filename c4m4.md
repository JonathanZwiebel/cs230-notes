# Face Recognition and Neural Style Transfer

# What is Face Recognition?
Face verification:
 - Given input image and name or ID
 - Determine if the image is that of the claimed person

Face recognition:
 - Database of K people
 - Get an input image
 - Output ID if the image is one of the people or not recognized

# One-shot Learning
Each person has only a single image
Image --> CNN --> Softmax is one possible implementation 
This doesn't work well b/c the training set is small
IF a new person joins the team then you don't want to retrain

Learn a similarity function
We learn d(img1, img2)
If d(img1, img2) < τ then you predict they are the same person

# Siamese Network
Image --> CNN --> Output layer (not softmax)
Output layer is f(x) where x is an input image
f(x) is an encoding of x
You compare the distance between two images with SSD(f(x1), f(x2))

We want parameters of a CNN such that similar pictures have a low SSD and that different pictures have
a high SSD

# Triplet Loss
Always have anchor, positive, negative
Maximize distance btwn anchor and negative
Minimize distance btwn anchor and positive

Want SSD(A, P) <= SSD(A, N)
We want SSD(A, P) - SSD(A, N) <= -α
This means we want
SSD(A, P) - SSD(A, N) + α <= 0

Loss is max(SSD(A, P) - SSD(A, N) + α, 0)
If it works than our loss is just 0 

To generate training data you need sets of images of the same person
If A, P, and N are randomly chosen then the constraint is easily to satisfy

Choose triplets that are hard to train on
You want ones where SSD(A, P) is high and SSD(A, N) is low 

XNet
DeepX

Just buy or take parameters from online

# Face Verification and Binary Classification
ex: Compute encodings
Two encodings together input into logistic regression for a prob that is being the same value

Typically you take the sigmoid of abs(sum(w_i)|f(x^i) - f(x^j)|) + b
χ^2 similarity is (a-b)^2/(a+b)

You can precompute the embeddings in the database
Training set is pairs of people matched with a value for same or different

# What is Neural Style Transfer
Content image is c
Style image is s
Generated image is g

# What are Deep Conv Nets Learning
Pick a unit in a layer 1
Find the image patches that maximize the unit's activation
Check other hidden units in layer 1 and check what activates them
Trained hidden units in layer 1 are looking for relatively simple features

Deeper units see more pixels from the input image
Deeper units work on more complex features

# Cost Functions
J(G) is our cost function which we minimize through standard parts
J(G) = αJ_content(C, G) + βJ_style(S, G)

Initiate G randomly
Use J(G) to update G
G := G - df*J(g)

Gradient descent is changing G

# Content Cost Function
J_content(C, G)

We are using a hidden layer l to compute content cost
Earlier layers are checking pixels / shapes
Later layers are checking objects / complex features
l is chosen to be in ht emiddle

Use a pre-trained CNN and find a^[l](c) and a^[l](g), activations on layer l
J_content(C, G) = 1/2 * SSD(a^[l](c), a^[l](g))
Incentives algorithm to find G that has similar a^[l](g)

# Style Cost Function
Style is correlation between activations across channels
Choose a layer l
Figure out how correlated the activations are across channels

For each channel take the activations
Find the correlation between the activations in each pair of channels
Figures out which texture components occur together or apart

Style matrix
a^[l]_{i,j,k}
i and j index across the image, k indexes across channel
G^[l] is n_c by n_c matrix
G^[l] shows the correlation between two values
G^[l]_{kk'} = sum_i sum_j (a^[l]_{i,j,k} * a^[l]_{i,j,k'})

G are Gram matrices

Compute style matrix for generated image
Compute style matrix for style iamge
J_style(C, G) = SSD(C style matrix, G style matrix)

Best style cost function occurs when you use multiple different layers
Each layer should have a different weight

# 1D and 3D Generalizations
1D convolution is just a vector
